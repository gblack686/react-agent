version: '3.8'

services:
  # LangGraph Agent Service
  langgraph-agent:
    build:
      context: .
      dockerfile: Dockerfile
    ports:
      - "8000:8000"
    environment:
      - TAVILY_API_KEY=${TAVILY_API_KEY}
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY}
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - MCP_SERVER_URL=http://host.docker.internal:8080  # Points to host machine for local testing
    volumes:
      - .:/app
    command: uvicorn src.app:app --host 0.0.0.0 --port 8000 --reload

  # Jina AI MCP Server
  jina-mcp:
    image: node:18-slim
    working_dir: /app
    ports:
      - "8080:8080"
    environment:
      - MCP_API_KEY=${JINA_MCP_API_KEY}
    volumes:
      - ./mcp:/app
    command: >
      bash -c "npm install -g @smithery/cli && 
               smithery install jina-ai-mcp-server --client claude &&
               cd .smithery && 
               npm start"

  # LangGraph Studio
  langgraph-studio:
    image: ghcr.io/langchain-ai/langgraph-studio:latest
    ports:
      - "3000:3000"
    environment:
      - BACKEND_URL=http://langgraph-agent:8000

networks:
  agent-network:
    driver: bridge 